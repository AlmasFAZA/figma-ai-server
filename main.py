from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import base64
import openai
import os

# üîê –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (–Ω–µ –≤—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä—è–º–æ –≤ –∫–æ–¥)
openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# ‚úÖ CORS –¥–ª—è Figma Web
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ImageRequest(BaseModel):
    image: str  # base64 PNG –∏–ª–∏ JPG

@app.post("/analyze")
async def analyze(request: ImageRequest):
    image_data = request.image.replace("data:image/png;base64,", "").replace("data:image/jpeg;base64,", "")
    image_bytes = base64.b64decode(image_data)

    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "–¢—ã ‚Äî UI-–¥–∏–∑–∞–π–Ω–µ—Ä. –ù–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–∑–¥–∞–π JSON —Å –±–ª–æ–∫–∞–º–∏, —Ç–µ–∫—Å—Ç–∞–º–∏ –∏ –∫–Ω–æ–ø–∫–∞–º–∏ –¥–ª—è –º–∞–∫–µ—Ç–∞ –≤ Figma. –ò–≥–Ω–æ—Ä–∏—Ä—É–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∫–∞–∫ JSON: blocks, texts, buttons, sections."
            },
            {
                "role": "user",
                "content": [
                    { "type": "text", "text": "–°–æ–∑–¥–∞–π JSON-–º–∞–∫–µ—Ç –∏–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏." },
                    {
                        "type": "image_url",
                        "image_url": { "url": "data:image/png;base64," + image_data }
                    }
                ]
            }
        ],
        temperature=0.2,
        max_tokens=2000
    )

    content = response.choices[0].message.content
    try:
        json_data = eval(content)
    except:
        return { "error": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON", "raw": content }

    return json_data